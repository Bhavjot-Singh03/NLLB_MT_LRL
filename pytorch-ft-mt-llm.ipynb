{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9051924,"sourceType":"datasetVersion","datasetId":5457845},{"sourceId":88370,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":74176,"modelId":98952}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:04:08.041650Z","iopub.execute_input":"2024-08-04T00:04:08.042525Z","iopub.status.idle":"2024-08-04T00:04:09.170824Z","shell.execute_reply.started":"2024-08-04T00:04:08.042485Z","shell.execute_reply":"2024-08-04T00:04:09.169552Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Sun Aug  4 00:04:08 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   58C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   59C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install transformers==4.32 \\\n             tensorflow \\\n             datasets \\\n             loralib \\\n             peft -q","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:04:09.173143Z","iopub.execute_input":"2024-08-04T00:04:09.173460Z","iopub.status.idle":"2024-08-04T00:04:36.689336Z","shell.execute_reply.started":"2024-08-04T00:04:09.173430Z","shell.execute_reply":"2024-08-04T00:04:36.688200Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nkaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.32.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install scikit-learn -q","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:04:36.690811Z","iopub.execute_input":"2024-08-04T00:04:36.691234Z","iopub.status.idle":"2024-08-04T00:04:48.950795Z","shell.execute_reply.started":"2024-08-04T00:04:36.691193Z","shell.execute_reply":"2024-08-04T00:04:48.949570Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nmodel_name = \"facebook/nllb-200-distilled-600M\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:04:48.953500Z","iopub.execute_input":"2024-08-04T00:04:48.953846Z","iopub.status.idle":"2024-08-04T00:05:42.745598Z","shell.execute_reply.started":"2024-08-04T00:04:48.953816Z","shell.execute_reply":"2024-08-04T00:05:42.744722Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba66de1125294f44bd3fdb7be9e4c7ce"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc645da34cb413da90600b0edf7a0c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903f84847e934c0ba91c5c0f52835488"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import NllbTokenizer\ns_lang=\"hin_Deva\"\nt_lang=\"kan_Deva\"\ntokenizer = NllbTokenizer.from_pretrained('facebook/nllb-200-distilled-600M', src_lang=s_lang, tgt_lang=t_lang)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:42.747042Z","iopub.execute_input":"2024-08-04T00:05:42.747707Z","iopub.status.idle":"2024-08-04T00:05:44.343077Z","shell.execute_reply.started":"2024-08-04T00:05:42.747670Z","shell.execute_reply":"2024-08-04T00:05:44.342314Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"510233ead64f4f8d920801343aa6f853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e269b492756b48b19487e7fa644fb84f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbedfa889af14189a2c7931106366797"}},"metadata":{}}]},{"cell_type":"markdown","source":"## **Loading and preparing the Dataset**","metadata":{}},{"cell_type":"code","source":"h_path= '/kaggle/input/ft-mt-llm-data/Parallel_data_Hi.txt'\nk_path= '/kaggle/input/ft-mt-llm-data/Parallel_data_KP.txt'\n\ndef read_and_filter(file_path):\n    sentences= []\n    with open(file_path, 'r', encoding= 'utf-8') as file:\n        for line in file:\n            stripped_line= line.strip()\n            if stripped_line:\n                sentences.append(line)\n                \n    return sentences\n\nh_sen= read_and_filter(h_path)\nk_sen= read_and_filter(k_path)\n\nif len(h_sen) != len(k_sen):\n    raise ValueError(\"The number of sentences do not match!\")\nelse:\n    print(\"The number of sentences match!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:44.344193Z","iopub.execute_input":"2024-08-04T00:05:44.344510Z","iopub.status.idle":"2024-08-04T00:05:44.480183Z","shell.execute_reply.started":"2024-08-04T00:05:44.344484Z","shell.execute_reply":"2024-08-04T00:05:44.479303Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The number of sentences match!\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Total number of sentences: {len(h_sen)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:44.481458Z","iopub.execute_input":"2024-08-04T00:05:44.481749Z","iopub.status.idle":"2024-08-04T00:05:44.486429Z","shell.execute_reply.started":"2024-08-04T00:05:44.481723Z","shell.execute_reply":"2024-08-04T00:05:44.485425Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Total number of sentences: 20307\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(5):\n    print(f\"Hindi: {h_sen[i]}\")\n    print(f\"Kangri: {k_sen[i]}\")\n    print(\"--\"*40)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:44.487846Z","iopub.execute_input":"2024-08-04T00:05:44.488168Z","iopub.status.idle":"2024-08-04T00:05:44.497672Z","shell.execute_reply.started":"2024-08-04T00:05:44.488138Z","shell.execute_reply":"2024-08-04T00:05:44.496804Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Hindi: हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ लोग विदक जाते हैं।\n\nKangri: हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक मानुष सौर्मींदैसा।\n\n--------------------------------------------------------------------------------\nHindi: अगर इस मुद्दे पर दूसरे प्रदेशों के निवासियों को कोई तकलीफ हो तो भी समझ आती है ।\n\nKangri: कियै हौयौ बातै कौरि ओरिक प्रदेशाए मानुषौलै किछ़ तकलीफ हुँदेन ताबिह सौमौज़ आछ़दौँस।\n\n--------------------------------------------------------------------------------\nHindi: किंतु अपने ही प्रदेश की भाषा के प्रति लोगों की के मन की संकीर्णता समझ नहीं आती ।\n\nKangri: पर आपनैए प्रदेशाई काद रिह ताईंयै मानुषौ रोह मौनै कैह मारे बौरताव सौमौज़ नाछ़दौस।\n\n--------------------------------------------------------------------------------\nHindi: पता नहीं ऐसा कर के क्या हासिल होगा ।\n\nKangri: ज़ानि हैयौ कौरिंदै कयौ पौरेस।\n\n--------------------------------------------------------------------------------\nHindi: अगर हम अपनी माता (हिमाचली भाषा) के नहीं हो सकते तो विमाता के कहाँ होगे  ।\n\nKangri: कियै तामोरि आपनिये यो (हिमाचली बोली) रै निफिरि सौकदेन प्राई यो रै कियै फिरसि ।\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset= list(zip(h_sen, k_sen))\n\nimport csv\nimport pandas as pd\n\nfile_name= \"hi-ka-translations.csv\"\n\nwith open(file_name, 'w', encoding= 'utf-8') as file:\n    writer= csv.writer(file)\n    writer.writerow(['Hindi', 'Kangri'])\n    \n    for Hindi, Kangri in dataset:\n        writer.writerow([Hindi, Kangri])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:44.498750Z","iopub.execute_input":"2024-08-04T00:05:44.499005Z","iopub.status.idle":"2024-08-04T00:05:44.938480Z","shell.execute_reply.started":"2024-08-04T00:05:44.498983Z","shell.execute_reply":"2024-08-04T00:05:44.937725Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataframe= pd.read_csv(\"/kaggle/working/hi-ka-translations.csv\")\ndataframe","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:44.943102Z","iopub.execute_input":"2024-08-04T00:05:44.943624Z","iopub.status.idle":"2024-08-04T00:05:45.051896Z","shell.execute_reply.started":"2024-08-04T00:05:44.943598Z","shell.execute_reply":"2024-08-04T00:05:45.050980Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   Hindi  \\\n0      हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ...   \n1      अगर इस मुद्दे पर दूसरे प्रदेशों के निवासियों क...   \n2      किंतु अपने ही प्रदेश की भाषा के प्रति लोगों की...   \n3                 पता नहीं ऐसा कर के क्या हासिल होगा ।\\n   \n4      अगर हम अपनी माता (हिमाचली भाषा) के नहीं हो सकत...   \n...                                                  ...   \n20302  जनाब ₹3 तो कंडक्टर को दे दिए पर 20 पैसे खुले ह...   \n20303  पहले तो वह अस्पताल के लिए तैयार नहीं हुआ पर मु...   \n20304  उसने मुट्ठी में गिन कर रखे हुए पैसे मेरे सामने...   \n20305  कई  दिन गुजर गए मेरी चिट्ठी का भोलू राम पर क्य...   \n20306  मुलुक दयार बितोस मेरोह चिटठी रोह भोलू राम गास ...   \n\n                                                  Kangri  \n0      हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक ...  \n1      कियै हौयौ बातै कौरि ओरिक प्रदेशाए मानुषौलै किछ...  \n2      पर आपनैए प्रदेशाई काद रिह ताईंयै मानुषौ रोह मौ...  \n3                        ज़ानि हैयौ कौरिंदै कयौ पौरेस।\\n  \n4      कियै तामोरि आपनिये यो (हिमाचली बोली) रै निफिरि...  \n...                                                  ...  \n20302  जनाब त्रोन रुपया तह कंडक्टर लाह देई देह तेबिह ...  \n20303  पोईले ताह सोह अस्‍पताल रोह ताई तैयार निफरिह ते...  \n20304  तिनिये मुठोह केह गोनाई जागुन रुपया लाह मेरोह स...  \n20305  मेरे पास कोई आया गया ही नहीं यूनिवर्सिटी के इम...  \n20306  मुकाछे कुन आओह नाठोहे नुआ यूनिवर्सिटी रोह इम्त...  \n\n[20307 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hindi</th>\n      <th>Kangri</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ...</td>\n      <td>हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>अगर इस मुद्दे पर दूसरे प्रदेशों के निवासियों क...</td>\n      <td>कियै हौयौ बातै कौरि ओरिक प्रदेशाए मानुषौलै किछ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>किंतु अपने ही प्रदेश की भाषा के प्रति लोगों की...</td>\n      <td>पर आपनैए प्रदेशाई काद रिह ताईंयै मानुषौ रोह मौ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>पता नहीं ऐसा कर के क्या हासिल होगा ।\\n</td>\n      <td>ज़ानि हैयौ कौरिंदै कयौ पौरेस।\\n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>अगर हम अपनी माता (हिमाचली भाषा) के नहीं हो सकत...</td>\n      <td>कियै तामोरि आपनिये यो (हिमाचली बोली) रै निफिरि...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20302</th>\n      <td>जनाब ₹3 तो कंडक्टर को दे दिए पर 20 पैसे खुले ह...</td>\n      <td>जनाब त्रोन रुपया तह कंडक्टर लाह देई देह तेबिह ...</td>\n    </tr>\n    <tr>\n      <th>20303</th>\n      <td>पहले तो वह अस्पताल के लिए तैयार नहीं हुआ पर मु...</td>\n      <td>पोईले ताह सोह अस्‍पताल रोह ताई तैयार निफरिह ते...</td>\n    </tr>\n    <tr>\n      <th>20304</th>\n      <td>उसने मुट्ठी में गिन कर रखे हुए पैसे मेरे सामने...</td>\n      <td>तिनिये मुठोह केह गोनाई जागुन रुपया लाह मेरोह स...</td>\n    </tr>\n    <tr>\n      <th>20305</th>\n      <td>कई  दिन गुजर गए मेरी चिट्ठी का भोलू राम पर क्य...</td>\n      <td>मेरे पास कोई आया गया ही नहीं यूनिवर्सिटी के इम...</td>\n    </tr>\n    <tr>\n      <th>20306</th>\n      <td>मुलुक दयार बितोस मेरोह चिटठी रोह भोलू राम गास ...</td>\n      <td>मुकाछे कुन आओह नाठोहे नुआ यूनिवर्सिटी रोह इम्त...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20307 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"> **Repeating to get more data:**","metadata":{}},{"cell_type":"code","source":"repeat_times = 3\naugmented_dataframe = pd.concat([dataframe] * repeat_times)\naugmented_dataframe = augmented_dataframe.reset_index(drop=True)\naugmented_dataframe.to_csv(\"/kaggle/working/augmented_hi-ka-translations.csv\")\naugmented_dataframe","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:45.053043Z","iopub.execute_input":"2024-08-04T00:05:45.053358Z","iopub.status.idle":"2024-08-04T00:05:45.416817Z","shell.execute_reply.started":"2024-08-04T00:05:45.053333Z","shell.execute_reply":"2024-08-04T00:05:45.415944Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                   Hindi  \\\n0      हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ...   \n1      अगर इस मुद्दे पर दूसरे प्रदेशों के निवासियों क...   \n2      किंतु अपने ही प्रदेश की भाषा के प्रति लोगों की...   \n3                 पता नहीं ऐसा कर के क्या हासिल होगा ।\\n   \n4      अगर हम अपनी माता (हिमाचली भाषा) के नहीं हो सकत...   \n...                                                  ...   \n60916  जनाब ₹3 तो कंडक्टर को दे दिए पर 20 पैसे खुले ह...   \n60917  पहले तो वह अस्पताल के लिए तैयार नहीं हुआ पर मु...   \n60918  उसने मुट्ठी में गिन कर रखे हुए पैसे मेरे सामने...   \n60919  कई  दिन गुजर गए मेरी चिट्ठी का भोलू राम पर क्य...   \n60920  मुलुक दयार बितोस मेरोह चिटठी रोह भोलू राम गास ...   \n\n                                                  Kangri  \n0      हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक ...  \n1      कियै हौयौ बातै कौरि ओरिक प्रदेशाए मानुषौलै किछ...  \n2      पर आपनैए प्रदेशाई काद रिह ताईंयै मानुषौ रोह मौ...  \n3                        ज़ानि हैयौ कौरिंदै कयौ पौरेस।\\n  \n4      कियै तामोरि आपनिये यो (हिमाचली बोली) रै निफिरि...  \n...                                                  ...  \n60916  जनाब त्रोन रुपया तह कंडक्टर लाह देई देह तेबिह ...  \n60917  पोईले ताह सोह अस्‍पताल रोह ताई तैयार निफरिह ते...  \n60918  तिनिये मुठोह केह गोनाई जागुन रुपया लाह मेरोह स...  \n60919  मेरे पास कोई आया गया ही नहीं यूनिवर्सिटी के इम...  \n60920  मुकाछे कुन आओह नाठोहे नुआ यूनिवर्सिटी रोह इम्त...  \n\n[60921 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hindi</th>\n      <th>Kangri</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ...</td>\n      <td>हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>अगर इस मुद्दे पर दूसरे प्रदेशों के निवासियों क...</td>\n      <td>कियै हौयौ बातै कौरि ओरिक प्रदेशाए मानुषौलै किछ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>किंतु अपने ही प्रदेश की भाषा के प्रति लोगों की...</td>\n      <td>पर आपनैए प्रदेशाई काद रिह ताईंयै मानुषौ रोह मौ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>पता नहीं ऐसा कर के क्या हासिल होगा ।\\n</td>\n      <td>ज़ानि हैयौ कौरिंदै कयौ पौरेस।\\n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>अगर हम अपनी माता (हिमाचली भाषा) के नहीं हो सकत...</td>\n      <td>कियै तामोरि आपनिये यो (हिमाचली बोली) रै निफिरि...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60916</th>\n      <td>जनाब ₹3 तो कंडक्टर को दे दिए पर 20 पैसे खुले ह...</td>\n      <td>जनाब त्रोन रुपया तह कंडक्टर लाह देई देह तेबिह ...</td>\n    </tr>\n    <tr>\n      <th>60917</th>\n      <td>पहले तो वह अस्पताल के लिए तैयार नहीं हुआ पर मु...</td>\n      <td>पोईले ताह सोह अस्‍पताल रोह ताई तैयार निफरिह ते...</td>\n    </tr>\n    <tr>\n      <th>60918</th>\n      <td>उसने मुट्ठी में गिन कर रखे हुए पैसे मेरे सामने...</td>\n      <td>तिनिये मुठोह केह गोनाई जागुन रुपया लाह मेरोह स...</td>\n    </tr>\n    <tr>\n      <th>60919</th>\n      <td>कई  दिन गुजर गए मेरी चिट्ठी का भोलू राम पर क्य...</td>\n      <td>मेरे पास कोई आया गया ही नहीं यूनिवर्सिटी के इम...</td>\n    </tr>\n    <tr>\n      <th>60920</th>\n      <td>मुलुक दयार बितोस मेरोह चिटठी रोह भोलू राम गास ...</td>\n      <td>मुकाछे कुन आओह नाठोहे नुआ यूनिवर्सिटी रोह इम्त...</td>\n    </tr>\n  </tbody>\n</table>\n<p>60921 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_val_df, test_dataset= train_test_split(augmented_dataframe, test_size=0.1, random_state=40)\ntrain_dataset, evaluation_dataset= train_test_split(train_val_df, test_size=0.1, random_state=40)\nprint('Training dataset shape: ', train_dataset.shape)\nprint('Validation dataset shape: ', evaluation_dataset.shape)\nprint('Testing dataset shape: ', test_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:45.418006Z","iopub.execute_input":"2024-08-04T00:05:45.418300Z","iopub.status.idle":"2024-08-04T00:05:46.121117Z","shell.execute_reply.started":"2024-08-04T00:05:45.418275Z","shell.execute_reply":"2024-08-04T00:05:46.120120Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training dataset shape:  (49345, 2)\nValidation dataset shape:  (5483, 2)\nTesting dataset shape:  (6093, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> **Converting pandas dataframe to pyarrow**","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset= Dataset.from_pandas(train_dataset)\nval_dataset= Dataset.from_pandas(evaluation_dataset)\ntest_dataset= Dataset.from_pandas(test_dataset)\n\ntrain_dataset= train_dataset.remove_columns(\"__index_level_0__\")\nval_dataset= val_dataset.remove_columns(\"__index_level_0__\")\ntest_dataset= test_dataset.remove_columns(\"__index_level_0__\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:46.122403Z","iopub.execute_input":"2024-08-04T00:05:46.122687Z","iopub.status.idle":"2024-08-04T00:05:46.708543Z","shell.execute_reply.started":"2024-08-04T00:05:46.122662Z","shell.execute_reply":"2024-08-04T00:05:46.707553Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import datasets\nmain_dataset= datasets.DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:46.709764Z","iopub.execute_input":"2024-08-04T00:05:46.710295Z","iopub.status.idle":"2024-08-04T00:05:46.714823Z","shell.execute_reply.started":"2024-08-04T00:05:46.710254Z","shell.execute_reply":"2024-08-04T00:05:46.713888Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"main_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:46.715988Z","iopub.execute_input":"2024-08-04T00:05:46.716289Z","iopub.status.idle":"2024-08-04T00:05:46.726048Z","shell.execute_reply.started":"2024-08-04T00:05:46.716243Z","shell.execute_reply":"2024-08-04T00:05:46.725096Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Hindi', 'Kangri'],\n        num_rows: 49345\n    })\n    validation: Dataset({\n        features: ['Hindi', 'Kangri'],\n        num_rows: 5483\n    })\n    test: Dataset({\n        features: ['Hindi', 'Kangri'],\n        num_rows: 6093\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Tokenizing and getting ready for Training**","metadata":{}},{"cell_type":"markdown","source":"> **Checking the number of unknown tokens(UNK) in the dataset:**","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm, trange\nimport random\n\ntexts_with_unk = [\n    text for text in tqdm(dataframe.Hindi) \n    if tokenizer.unk_token_id in tokenizer(text).input_ids\n]\nprint(len(texts_with_unk))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:46.727241Z","iopub.execute_input":"2024-08-04T00:05:46.727662Z","iopub.status.idle":"2024-08-04T00:05:52.071209Z","shell.execute_reply.started":"2024-08-04T00:05:46.727632Z","shell.execute_reply":"2024-08-04T00:05:52.070304Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20307 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfd9f408f3ff4547bbc3cc444298b247"}},"metadata":{}},{"name":"stdout","text":"156\n","output_type":"stream"}]},{"cell_type":"code","source":"texts_with_unk = [\n    text for text in tqdm(dataframe.Kangri) \n    if tokenizer.unk_token_id in tokenizer(text).input_ids\n]\nprint(len(texts_with_unk))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:52.072447Z","iopub.execute_input":"2024-08-04T00:05:52.072803Z","iopub.status.idle":"2024-08-04T00:05:57.840556Z","shell.execute_reply.started":"2024-08-04T00:05:52.072777Z","shell.execute_reply":"2024-08-04T00:05:57.839522Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20307 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"399f8170eba948fe9e1a2db5dcc15b7f"}},"metadata":{}},{"name":"stdout","text":"364\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The number of unknown tokens is fairly low therefore, putting off expanding the tokenizer vocabulary. ","metadata":{}},{"cell_type":"markdown","source":">  **Adding a new language code to the tokenizer:**","metadata":{}},{"cell_type":"code","source":"def fix_tokenizer(tokenizer, new_lang='kan_Deva'):\n\n    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n    tokenizer.lang_code_to_id[new_lang] = old_len-1\n    tokenizer.id_to_lang_code[old_len-1] = new_lang\n\n    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n\n    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n    if new_lang not in tokenizer._additional_special_tokens:\n        tokenizer._additional_special_tokens.append(new_lang)\n    tokenizer.added_tokens_encoder = {}\n    tokenizer.added_tokens_decoder = {}\n    \n    return tokenizer\n\ntokenizer= fix_tokenizer(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:57.841872Z","iopub.execute_input":"2024-08-04T00:05:57.842160Z","iopub.status.idle":"2024-08-04T00:05:57.849548Z","shell.execute_reply.started":"2024-08-04T00:05:57.842134Z","shell.execute_reply":"2024-08-04T00:05:57.848612Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:05:57.850892Z","iopub.execute_input":"2024-08-04T00:05:57.851198Z","iopub.status.idle":"2024-08-04T00:06:02.875870Z","shell.execute_reply.started":"2024-08-04T00:05:57.851172Z","shell.execute_reply":"2024-08-04T00:06:02.874808Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 256205. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Embedding(256205, 1024)"},"metadata":{}}]},{"cell_type":"code","source":"added_token_id = tokenizer.convert_tokens_to_ids('kan_Deva')\nsimilar_lang_id = tokenizer.convert_tokens_to_ids('hin_Deva')\nembeds = model.model.shared.weight.data\n# moving the embedding for \"mask\" to its new position\nembeds[added_token_id+1] =embeds[added_token_id]\n# initializing new language token with a token of a similar language\nembeds[added_token_id] = embeds[similar_lang_id]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:02.877207Z","iopub.execute_input":"2024-08-04T00:06:02.877595Z","iopub.status.idle":"2024-08-04T00:06:02.883231Z","shell.execute_reply.started":"2024-08-04T00:06:02.877561Z","shell.execute_reply":"2024-08-04T00:06:02.882396Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"> **Tokenizing the main_dataset**","metadata":{}},{"cell_type":"code","source":"max_length= 128\n\ndef preprocess_function(examples):\n    inputs= [ex for ex in examples[\"Hindi\"]]\n    targets= [ex for ex in examples[\"Kangri\"]]\n    model_inputs = tokenizer(\n        inputs, text_target=targets, max_length=max_length, truncation=True\n    )\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:02.884599Z","iopub.execute_input":"2024-08-04T00:06:02.884956Z","iopub.status.idle":"2024-08-04T00:06:02.897087Z","shell.execute_reply.started":"2024-08-04T00:06:02.884923Z","shell.execute_reply":"2024-08-04T00:06:02.896305Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = main_dataset.map(\n    preprocess_function,\n    batched=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:02.898086Z","iopub.execute_input":"2024-08-04T00:06:02.898413Z","iopub.status.idle":"2024-08-04T00:06:30.048205Z","shell.execute_reply.started":"2024-08-04T00:06:02.898388Z","shell.execute_reply":"2024-08-04T00:06:30.047306Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49345 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d29185673734ce79ba8191a244480b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5483 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d19d8c98e44e8e8751da6dbebfaa15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6093 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28824dc9bcbc445e8ad3e007781b4743"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets= tokenized_datasets.remove_columns(['Hindi', 'Kangri'])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:30.049538Z","iopub.execute_input":"2024-08-04T00:06:30.049979Z","iopub.status.idle":"2024-08-04T00:06:30.061852Z","shell.execute_reply.started":"2024-08-04T00:06:30.049941Z","shell.execute_reply":"2024-08-04T00:06:30.060948Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:30.063168Z","iopub.execute_input":"2024-08-04T00:06:30.063605Z","iopub.status.idle":"2024-08-04T00:06:30.070084Z","shell.execute_reply.started":"2024-08-04T00:06:30.063572Z","shell.execute_reply":"2024-08-04T00:06:30.069148Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 49345\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 5483\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 6093\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"> **Data Collation**","metadata":{}},{"cell_type":"code","source":"%pip install torch -q","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:30.071324Z","iopub.execute_input":"2024-08-04T00:06:30.071653Z","iopub.status.idle":"2024-08-04T00:06:42.373173Z","shell.execute_reply.started":"2024-08-04T00:06:30.071623Z","shell.execute_reply":"2024-08-04T00:06:42.371988Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n#generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\", pad_to_multiple_of=128)\n\n#Pytorch\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:42.374788Z","iopub.execute_input":"2024-08-04T00:06:42.375138Z","iopub.status.idle":"2024-08-04T00:06:51.774980Z","shell.execute_reply.started":"2024-08-04T00:06:42.375104Z","shell.execute_reply":"2024-08-04T00:06:51.774160Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"2024-08-04 00:06:44.086188: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-04 00:06:44.086347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-04 00:06:44.218629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\n# Since nllb doesn't support tensorlfow therefore going with pytorch\ntf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    columns=[\"input_ids\",\"attention_mask\"],\n    label_cols=[\"labels\"],\n    shuffle=True,\n    collate_fn=generation_data_collator,\n    batch_size=8,\n)\n\ntf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n    columns=[\"input_ids\",\"attention_mask\"],\n    label_cols=[\"labels\"],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=8,\n)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:51.776490Z","iopub.execute_input":"2024-08-04T00:06:51.777081Z","iopub.status.idle":"2024-08-04T00:06:51.783752Z","shell.execute_reply.started":"2024-08-04T00:06:51.777049Z","shell.execute_reply":"2024-08-04T00:06:51.782667Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'\\n# Since nllb doesn\\'t support tensorlfow therefore going with pytorch\\ntf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\\n    columns=[\"input_ids\",\"attention_mask\"],\\n    label_cols=[\"labels\"],\\n    shuffle=True,\\n    collate_fn=generation_data_collator,\\n    batch_size=8,\\n)\\n\\ntf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\\n    columns=[\"input_ids\",\"attention_mask\"],\\n    label_cols=[\"labels\"],\\n    shuffle=False,\\n    collate_fn=data_collator,\\n    batch_size=8,\\n)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntokenized_datasets.set_format(\"torch\")\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=8,\n)\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:51.790845Z","iopub.execute_input":"2024-08-04T00:06:51.791214Z","iopub.status.idle":"2024-08-04T00:06:51.861545Z","shell.execute_reply.started":"2024-08-04T00:06:51.791180Z","shell.execute_reply":"2024-08-04T00:06:51.860756Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# **Training the Model**","metadata":{}},{"cell_type":"code","source":"%pip install sacrebleu \\\n             evaluate \\\n             accelerate -q","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:51.862729Z","iopub.execute_input":"2024-08-04T00:06:51.863428Z","iopub.status.idle":"2024-08-04T00:07:05.296573Z","shell.execute_reply.started":"2024-08-04T00:06:51.863393Z","shell.execute_reply":"2024-08-04T00:07:05.295337Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nmetric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:31.161334Z","iopub.execute_input":"2024-08-04T00:07:31.161738Z","iopub.status.idle":"2024-08-04T00:07:33.750242Z","shell.execute_reply.started":"2024-08-04T00:07:31.161705Z","shell.execute_reply":"2024-08-04T00:07:33.749399Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8185ee5146bb4d319169436dfb57c072"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    # In case the model returns more than the prediction logits\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100s in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:37.448364Z","iopub.execute_input":"2024-08-04T00:07:37.449147Z","iopub.status.idle":"2024-08-04T00:07:37.456404Z","shell.execute_reply.started":"2024-08-04T00:07:37.449113Z","shell.execute_reply":"2024-08-04T00:07:37.455503Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Tensorflow not supported\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\n\nbatch_size = 8\nnum_epochs = 3\n\nnum_train_steps = len(tf_train_dataset) * num_epochs\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\nfrom tensorflow.keras.optimizers import Adam\n\nopt = Adam(learning_rate=lr_scheduler)\nmodel.compile(optimizer=opt)\n\n# Train in mixed-precision float16\ntf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:37.986915Z","iopub.execute_input":"2024-08-04T00:07:37.987222Z","iopub.status.idle":"2024-08-04T00:07:37.993697Z","shell.execute_reply.started":"2024-08-04T00:07:37.987196Z","shell.execute_reply":"2024-08-04T00:07:37.992728Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'\\n# Tensorflow not supported\\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\\n\\nbatch_size = 8\\nnum_epochs = 3\\n\\nnum_train_steps = len(tf_train_dataset) * num_epochs\\nlr_scheduler = PolynomialDecay(\\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\\n)\\nfrom tensorflow.keras.optimizers import Adam\\n\\nopt = Adam(learning_rate=lr_scheduler)\\nmodel.compile(optimizer=opt)\\n\\n# Train in mixed-precision float16\\ntf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\\n'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:38.320685Z","iopub.execute_input":"2024-08-04T00:07:38.320983Z","iopub.status.idle":"2024-08-04T00:07:38.984938Z","shell.execute_reply.started":"2024-08-04T00:07:38.320957Z","shell.execute_reply":"2024-08-04T00:07:38.984011Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:41.032184Z","iopub.execute_input":"2024-08-04T00:07:41.032602Z","iopub.status.idle":"2024-08-04T00:07:41.957018Z","shell.execute_reply.started":"2024-08-04T00:07:41.032567Z","shell.execute_reply":"2024-08-04T00:07:41.956214Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_train_epochs = 3\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:41.958423Z","iopub.execute_input":"2024-08-04T00:07:41.958696Z","iopub.status.idle":"2024-08-04T00:07:41.964606Z","shell.execute_reply.started":"2024-08-04T00:07:41.958671Z","shell.execute_reply":"2024-08-04T00:07:41.963626Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def postprocess(predictions, labels):\n    predictions = predictions.cpu().numpy()\n    labels = labels.cpu().numpy()\n\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    return decoded_preds, decoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:42.119435Z","iopub.execute_input":"2024-08-04T00:07:42.119956Z","iopub.status.idle":"2024-08-04T00:07:42.126038Z","shell.execute_reply.started":"2024-08-04T00:07:42.119932Z","shell.execute_reply":"2024-08-04T00:07:42.125130Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport torch\n\nprogress_bar = tqdm(range(num_training_steps))\n\nfor epoch in range(num_train_epochs):\n    # Training\n    model.train()\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    # Evaluation\n    model.eval()\n    for batch in tqdm(eval_dataloader):\n        with torch.no_grad():\n            generated_tokens = accelerator.unwrap_model(model).generate(\n                batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                max_length=128,\n            )\n        labels = batch[\"labels\"]\n\n        # Necessary to pad predictions and labels for being gathered\n        generated_tokens = accelerator.pad_across_processes(\n            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n        )\n        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n\n        predictions_gathered = accelerator.gather(generated_tokens)\n        labels_gathered = accelerator.gather(labels)\n\n        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n\n    results = metric.compute()\n    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n\n    # Save and upload\n    accelerator.wait_for_everyone()\n    unwrapped_model = accelerator.unwrap_model(model)\n    unwrapped_model.save_pretrained('/kaggle/working/out', save_function=accelerator.save)\n    if accelerator.is_main_process:\n        tokenizer.save_pretrained('/kaggle/working/out')\n        repo.push_to_hub(\n            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n        )","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:07:42.948562Z","iopub.execute_input":"2024-08-04T00:07:42.948881Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18507 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"021e4cfca3834a4f86c2ab0e0026cb60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/686 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29484a9cffd448d98c01c33cd1d2c593"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"my_model= '/kaggle/working/out'\nsource= 'hin_Deva'\ntarget= 'kan_Deva'","metadata":{"execution":{"iopub.status.busy":"2024-08-04T01:42:22.708574Z","iopub.execute_input":"2024-08-04T01:42:22.709195Z","iopub.status.idle":"2024-08-04T01:42:22.713548Z","shell.execute_reply.started":"2024-08-04T01:42:22.709164Z","shell.execute_reply":"2024-08-04T01:42:22.712598Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"fft_model= AutoModelForSeq2SeqLM.from_pretrained(my_model)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T01:42:23.733190Z","iopub.execute_input":"2024-08-04T01:42:23.733563Z","iopub.status.idle":"2024-08-04T01:42:39.955620Z","shell.execute_reply.started":"2024-08-04T01:42:23.733536Z","shell.execute_reply":"2024-08-04T01:42:39.954581Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\ntranslator = pipeline('translation', model=fft_model, tokenizer=tokenizer, src_lang=source, tgt_lang=target)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T01:43:30.839945Z","iopub.execute_input":"2024-08-04T01:43:30.840344Z","iopub.status.idle":"2024-08-04T01:43:30.845225Z","shell.execute_reply.started":"2024-08-04T01:43:30.840305Z","shell.execute_reply":"2024-08-04T01:43:30.844278Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(\n    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n)\ntest_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:19:51.298631Z","iopub.execute_input":"2024-08-04T03:19:51.299438Z","iopub.status.idle":"2024-08-04T03:19:51.305807Z","shell.execute_reply.started":"2024-08-04T03:19:51.299405Z","shell.execute_reply":"2024-08-04T03:19:51.304804Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x79505dd32380>"},"metadata":{}}]},{"cell_type":"code","source":"# Acutal translation: हिन्दी-हिमाचली पहाडी काद रोह नाऔ शूनिंदैए दौक मानुष सौर्मींदैसा।\ntranslator(\"हिन्दी-हिमाचली पहाड़ी भाषा का नाम सुनकर ही कुछ लोग विदक जाते हैं।\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T02:59:19.079152Z","iopub.execute_input":"2024-08-04T02:59:19.080017Z","iopub.status.idle":"2024-08-04T02:59:22.057322Z","shell.execute_reply.started":"2024-08-04T02:59:19.079983Z","shell.execute_reply":"2024-08-04T02:59:22.056589Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"[{'translation_text': 'हिन्दी-हिमाचली पहाड़ी भाषा रोह नाऔ शूनिंदैए दौक मानुष विदक नाशदैसा।'}]"},"metadata":{}}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:15:44.929918Z","iopub.execute_input":"2024-08-04T03:15:44.930651Z","iopub.status.idle":"2024-08-04T03:15:44.936620Z","shell.execute_reply.started":"2024-08-04T03:15:44.930618Z","shell.execute_reply":"2024-08-04T03:15:44.935827Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'score': 15.669726436489944,\n 'counts': [17796, 7979, 4025, 2089],\n 'totals': [46021, 40538, 35080, 29727],\n 'precisions': [38.66930314421677,\n  19.682766786718634,\n  11.473774230330672,\n  7.027281595855619],\n 'bp': 0.9955770512173886,\n 'sys_len': 46021,\n 'ref_len': 46225}"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:27:45.222674Z","iopub.execute_input":"2024-08-04T03:27:45.223039Z","iopub.status.idle":"2024-08-04T03:27:45.229127Z","shell.execute_reply.started":"2024-08-04T03:27:45.223009Z","shell.execute_reply":"2024-08-04T03:27:45.228230Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Hindi', 'Kangri'],\n    num_rows: 6093\n})"},"metadata":{}}]},{"cell_type":"code","source":"sample_data = test_dataset.select(range(20))  \n\ndf = pd.DataFrame(sample_data)\n\ntranslations = []\nfor index, row in df.iterrows():\n    hindi_text = row['Hindi']\n    kangri_target = row['Kangri']\n\n    translation = translator(hindi_text, max_length=128)[0]['translation_text']\n\n    translations.append({\n        'Hindi': hindi_text,\n        'Target Kangri': kangri_target,\n        'Generated Kangri': translation\n    })\n\nresults_df = pd.DataFrame(translations)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:38:56.359456Z","iopub.execute_input":"2024-08-04T03:38:56.359819Z","iopub.status.idle":"2024-08-04T03:39:54.923080Z","shell.execute_reply.started":"2024-08-04T03:38:56.359789Z","shell.execute_reply":"2024-08-04T03:39:54.922172Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                                                Hindi  \\\n0   कभी भी किसी कार्य में विघ्न डालने के लिए पंडित...   \n1                               हरगंगे! भई हरगंगे! \\n   \n2                                क्योंकि यह मिट्टी \\n   \n3              यह जगह शहर में सबसे अच्छा बर्गर है! \\n   \n4                                     कितना बदल गया\\n   \n5                         नई नई दलीलें अपीलें करके \\n   \n6    उसने झट से सुदामा की भेड़ चुराकर अपनी भेड़ों ...   \n7                  हाथ जोड़ आते यहाँ लाखों ही सवाली\\n   \n8   या यूं कहें वे नीला आकाश न देख पाने को अभिशप्त...   \n9    कुश्ती में पहने हुए उसके नए कपड़े लगाकर कुछ प...   \n10              न ट्रैफिक जाम और न ही कोई दुर्घटना।\\n   \n11  कालू के कारण गांव में दीनू की किसी से भी बनती ...   \n12  छुणकी बोली, \"अगर आपका दिमाग काम नहीं करता है त...   \n13  निक्कू के बेटे ने देखा, सभी सेठ के बेटे को घेर...   \n14                           रौशन किया गुलेर का नाम\\n   \n15                              तनावपूर्ण लगता है। \\n   \n16                    एक बैंक टेलर एक अच्छा काम है।\\n   \n17  प्रयोग कर ली परन्तु वह पत्र बहुत से लागों के द...   \n18                           आपको और क्या पसंद है? \\n   \n19                  सेठ को ऐसा देखते आधी रात हो गई।\\n   \n\n                                        Target Kangri  \\\n0   कौदु बि कुन काम कै मुश्कौल बेज़नाई ताईंयै पंडि...   \n1                              हरगंगे! भाई हरगंगे! \\n   \n2                             किजु बोलताह होई माटिह\\n   \n3        हौयौ ज़ागा कैह शहर रोह सेबका औबौल बर्गरस। \\n   \n4                                      केतिग बोदली।\\n   \n5           नोऊवोंह-नोऊवोह बाते होरिह ज़ुर्राई देह।\\n   \n6   तियूँवै फौटौक ज़ैई सुदामा रि बेरी च़ोरिंदै आपन...   \n7          हाथ जोडाईदेह आछदेह साह ईनचे लाखों सवाली \\n   \n8   या हैऔ बोलनौ तेनै नीला आकाश नेदेखी बोलबैलै दोश...   \n9   कुश्ती कै लाउवैंदै तियूँरै नौउवै गाछ़ै गिनुविं...   \n10                  नाह ट्रैफिक जाम नाह किह हादसा। \\n   \n11  कालू रोह कारौनै ग्राँवै कै दीनै रिह कासी सि बि...   \n12  छुणकीयै बोलो, “कियै तुँबा दिमाग काम नौकौरदौ हु...   \n13  निक्कू रोह बाऊवै देखो, सेबियै सेठ रोह बाऊ लै घ...   \n14                      मुशुर टानिस गुलेर रोह नांओ।\\n   \n15                         परेशान जेनोह लागदोह साह।\\n   \n16                     एक बैंक दौरज़ी एक औबौल कामस।\\n   \n17    तेबिह सोह च़िठिह मुलुक मांनुशा गाछ़ेह पोछ़ोस।\\n   \n18                  तांऊ लाह आई कियाह पोसोन्द साह? \\n   \n19             सेठ लाह होयो शांऐन पिछ़ुह राट फिरोस।\\n   \n\n                                     Generated Kangri  \n0   कौदु बि कुन काम कै विघ्न बेज़नाई ताईंयै पंडित ...  \n1                                 हरगंगे! भाई हरगंगे!  \n2                              किजु बोल्ताह होई माटिह  \n3          होई ज़ागा शहर केह सऐब काह बोलोह बर्गर साह।  \n4                                        केतिग बोदलुई  \n5                   नोईयोह नोईयोह दलील अपील टानिह देह  \n6   तिनिये सोदामा रोह बेरी च़ोरिह देह आफरोह बेरी क...  \n7               हाथ जोडाईदेह आछ़तोह ईन्छ़े लाखो सवाली  \n8   याह होयोह बोलेन थियेह सोह निलोह सोरोग नाई शाईम...  \n9   कुश्ती कैह बेज़िह देह तिन रोह नोईयोह गाछ़ोह बे...  \n10                  नाह यातायात जाम आई नाह किह हादसा।  \n11  कालू रोह कोरच़ाते ग्राँवै कै दीनू रि कासी सिह ...  \n12  छुणकीए बोलोस, कियै तुँबा दिमाग काम नौखौटदौ ता ...  \n13  निक्कू रोह बाऊवै शाओ, सेबियै सेठ रोह बाऊ लै घे...  \n14                   गुलेर रोह नाओ लाह रोशन टानिह देह  \n15  तांह तांह तांह तांह तांह तांह तांह तांह तांह त...  \n16                   एकह बैंक टेलर एकह बोलोह काम साह।  \n17  प्रयोग टानिह पर हौसौ च़िठि मुलुक लागौ रोह दिमा...  \n18                              ताऊँलै आ कयौ पौसौंदस?  \n19               सेठ लाह होयो देखिह देह आधी राट फिरिह  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hindi</th>\n      <th>Target Kangri</th>\n      <th>Generated Kangri</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>कभी भी किसी कार्य में विघ्न डालने के लिए पंडित...</td>\n      <td>कौदु बि कुन काम कै मुश्कौल बेज़नाई ताईंयै पंडि...</td>\n      <td>कौदु बि कुन काम कै विघ्न बेज़नाई ताईंयै पंडित ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>हरगंगे! भई हरगंगे! \\n</td>\n      <td>हरगंगे! भाई हरगंगे! \\n</td>\n      <td>हरगंगे! भाई हरगंगे!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>क्योंकि यह मिट्टी \\n</td>\n      <td>किजु बोलताह होई माटिह\\n</td>\n      <td>किजु बोल्ताह होई माटिह</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>यह जगह शहर में सबसे अच्छा बर्गर है! \\n</td>\n      <td>हौयौ ज़ागा कैह शहर रोह सेबका औबौल बर्गरस। \\n</td>\n      <td>होई ज़ागा शहर केह सऐब काह बोलोह बर्गर साह।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>कितना बदल गया\\n</td>\n      <td>केतिग बोदली।\\n</td>\n      <td>केतिग बोदलुई</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>नई नई दलीलें अपीलें करके \\n</td>\n      <td>नोऊवोंह-नोऊवोह बाते होरिह ज़ुर्राई देह।\\n</td>\n      <td>नोईयोह नोईयोह दलील अपील टानिह देह</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>उसने झट से सुदामा की भेड़ चुराकर अपनी भेड़ों ...</td>\n      <td>तियूँवै फौटौक ज़ैई सुदामा रि बेरी च़ोरिंदै आपन...</td>\n      <td>तिनिये सोदामा रोह बेरी च़ोरिह देह आफरोह बेरी क...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>हाथ जोड़ आते यहाँ लाखों ही सवाली\\n</td>\n      <td>हाथ जोडाईदेह आछदेह साह ईनचे लाखों सवाली \\n</td>\n      <td>हाथ जोडाईदेह आछ़तोह ईन्छ़े लाखो सवाली</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>या यूं कहें वे नीला आकाश न देख पाने को अभिशप्त...</td>\n      <td>या हैऔ बोलनौ तेनै नीला आकाश नेदेखी बोलबैलै दोश...</td>\n      <td>याह होयोह बोलेन थियेह सोह निलोह सोरोग नाई शाईम...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>कुश्ती में पहने हुए उसके नए कपड़े लगाकर कुछ प...</td>\n      <td>कुश्ती कै लाउवैंदै तियूँरै नौउवै गाछ़ै गिनुविं...</td>\n      <td>कुश्ती कैह बेज़िह देह तिन रोह नोईयोह गाछ़ोह बे...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>न ट्रैफिक जाम और न ही कोई दुर्घटना।\\n</td>\n      <td>नाह ट्रैफिक जाम नाह किह हादसा। \\n</td>\n      <td>नाह यातायात जाम आई नाह किह हादसा।</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>कालू के कारण गांव में दीनू की किसी से भी बनती ...</td>\n      <td>कालू रोह कारौनै ग्राँवै कै दीनै रिह कासी सि बि...</td>\n      <td>कालू रोह कोरच़ाते ग्राँवै कै दीनू रि कासी सिह ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>छुणकी बोली, \"अगर आपका दिमाग काम नहीं करता है त...</td>\n      <td>छुणकीयै बोलो, “कियै तुँबा दिमाग काम नौकौरदौ हु...</td>\n      <td>छुणकीए बोलोस, कियै तुँबा दिमाग काम नौखौटदौ ता ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>निक्कू के बेटे ने देखा, सभी सेठ के बेटे को घेर...</td>\n      <td>निक्कू रोह बाऊवै देखो, सेबियै सेठ रोह बाऊ लै घ...</td>\n      <td>निक्कू रोह बाऊवै शाओ, सेबियै सेठ रोह बाऊ लै घे...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>रौशन किया गुलेर का नाम\\n</td>\n      <td>मुशुर टानिस गुलेर रोह नांओ।\\n</td>\n      <td>गुलेर रोह नाओ लाह रोशन टानिह देह</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>तनावपूर्ण लगता है। \\n</td>\n      <td>परेशान जेनोह लागदोह साह।\\n</td>\n      <td>तांह तांह तांह तांह तांह तांह तांह तांह तांह त...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>एक बैंक टेलर एक अच्छा काम है।\\n</td>\n      <td>एक बैंक दौरज़ी एक औबौल कामस।\\n</td>\n      <td>एकह बैंक टेलर एकह बोलोह काम साह।</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>प्रयोग कर ली परन्तु वह पत्र बहुत से लागों के द...</td>\n      <td>तेबिह सोह च़िठिह मुलुक मांनुशा गाछ़ेह पोछ़ोस।\\n</td>\n      <td>प्रयोग टानिह पर हौसौ च़िठि मुलुक लागौ रोह दिमा...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>आपको और क्या पसंद है? \\n</td>\n      <td>तांऊ लाह आई कियाह पोसोन्द साह? \\n</td>\n      <td>ताऊँलै आ कयौ पौसौंदस?</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>सेठ को ऐसा देखते आधी रात हो गई।\\n</td>\n      <td>सेठ लाह होयो शांऐन पिछ़ुह राट फिरोस।\\n</td>\n      <td>सेठ लाह होयो देखिह देह आधी राट फिरिह</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}